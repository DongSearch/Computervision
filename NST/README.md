# Neural Style Transfer (NST)

PyTorch ê¸°ë°˜ìœ¼ë¡œ êµ¬í˜„í•œ **Neural Style Transfer** í”„ë¡œì íŠ¸ì…ë‹ˆë‹¤.  
VGG-19 pretrained modelê³¼ Gram Matrix ê¸°ë°˜ style lossë¥¼ ì‚¬ìš©í•˜ì—¬  
ì½˜í…ì¸  ì´ë¯¸ì§€ì™€ ìŠ¤íƒ€ì¼ ì´ë¯¸ì§€ë¥¼ ê²°í•©í•˜ëŠ” ë‹¤ì–‘í•œ ì‹¤í—˜ì„ ìˆ˜í–‰í–ˆìŠµë‹ˆë‹¤.

ë³¸ í”„ë¡œì íŠ¸ëŠ” **í•˜ì´í¼íŒŒë¼ë¯¸í„°(Î±, Î²), layer ì„ íƒ, loss ì„¤ê³„ê°€  
ê²°ê³¼ ì´ë¯¸ì§€ì— ë¯¸ì¹˜ëŠ” ì˜í–¥**ì„ ë¶„ì„í•˜ëŠ” ë° ì¤‘ì ì„ ë‘¡ë‹ˆë‹¤.

---

## ğŸ“Œ Consequences
### original image
![hanok](https://github.com/user-attachments/assets/7c8e8bcd-465d-46ae-a96d-51db20e7eb2b) ![gihbri](https://github.com/user-attachments/assets/6c70fc0a-1344-4e53-bef2-e391d18919b4)


###  Alpha Variation
<img width="1415" height="956" alt="image" src="https://github.com/user-attachments/assets/8ac008ee-5475-47cb-a015-1924250d9802" />

* I observe that as the style weight (Î±) increases, more details from the style imageâ€”such as textures and colorsâ€”are incorporated into the output image.
### Extract from different layers
<img width="436" height="418" alt="image" src="https://github.com/user-attachments/assets/e723acf8-7846-4b27-8292-5424d4c62c80" />
<img width="398" height="421" alt="image" src="https://github.com/user-attachments/assets/ee430bd6-9389-4026-b304-35fcbafe1e50" />


 ### Tv_weight Variation
---

## ğŸ§  Experiment



## ğŸ“‰ Limitations

- Gram Matrix discards spatial information
- VGG features are texture-biased
- Difficult to achieve fully natural photo-level compositing
- Î± scaling alone cannot overcome strong content constraints

These limitations reflect the **fundamental constraints of  
VGG + Gram-based NST**, rather than implementation issues.

### Content Representation
- Extracted from intermediate VGG layers
- Default layer:
  - `r42`

### Style Representation
- Gram Matrix of feature maps
- Default layers:
  - `r21`, `r31`, `r41`, `r51`

---

## ğŸ§® Theory


---

